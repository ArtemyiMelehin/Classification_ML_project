# <center> Классическая задача бинарной классификации.

#### <center> Проект включает в себя 5 разделов:

## Оглавление
1. [Исследование структуры данных](#Исследование-структуры-данных)
2. [Разведывательный анализ](#разведывательный-анализ-и-визуализация)
3. [Преобразование-данных](#Преобразование-данных)
4. [Baseline задачи классификации](#Baseline-задачи-классификации)
5. [Продвинутые методы ML](#Продвинутые-методы-ML:-ансамбли,-бустинг)

## Исследование структуры данных
Здесь мы смотрим: 
- правильно ли загрузились наши данные
- из каких столбцов состоят данные, какого типа столбцы
- Посмотрим данные на наличие выбросов и дубликатов.

## Разведывательный анализ
Этот этап самый интересный, в нём мы при помощи библиотеки dtale изучаем данные на распределение, частоту появления и др.

Также мы визуализировали долю всех категориальных признаков относительно искомого признака deposit.

В итоге EDA, мы поняли большинство особенностей наших данных, но данные все ещё не готовы для ML-алгоритмов, тогда давайте это исправим!

## Преобразование-данных
Здесь мы хотим преобразить наши данные в такие, чтобы их смогли "переварить" наши будущие модели машинного обучения.

У нас есть 2 типа данных: 
    * категориальные 
    * числовые

Категориальные бинарные признаки мы кодируем LabelEncoder(), порядковые через OrdinalEncoder(), а номинальные через OneHotEncoder()

Также мы используем обработку выбросов метода Тьюки.

В конце данного этапа мы отбираем 15 самых важных признака для предсказания и работаем с ними.

## Baseline задачи классификации
Тут мы строим простые модели машинного обучения: LogisticRegression, DecissionTreeClassifier.

В ручную подбираем необходимые параметры и считаем метрики, в частности ориентируемся на F1-метрику.

Лучший результат при базовых настройка простых моделей f1=0.81

## Продвинутые методы ML: ансамбли, бустинг
Тут мы строим ансамбли, а также пользуемся стекингом. В дополнение к данным моделям мы оптимизируем подбор гиперпараметров с помощью GridSearch и библиотеки Optuna.

В итоге метрика F1 улучшилась, то есть повысилось качество предсказания модели.
## Данные

* Во вложение к проекту есть файл: bank_fin.csv, который и является исходными данными.

## Используемые зависимости
* Python (3.9):
    * [numpy (1.20.3)](https://numpy.org)
    * [pandas (1.3.4)](https://pandas.pydata.org)
    * [matplotlib (3.4.3)](https://matplotlib.org)
    * [seaborn (0.11.2)](https://seaborn.pydata.org)
    
## Установка проекта
```
    git clone https://github.com/ArtemyiMelehin/Classification_ML_project
```

## Использование
Вся информация о работе представлена в jupyter-ноутбуке Project_4_ML.ipynb.

## Авторы

* [Мелехин Артемий](https://vk.com/rationality1379)

## Выводы

Я решил классическую задачу классификацию, проведя почти полный цикл разработки проектов, достиг оптимальной предсказательной метрики. Также оставленны рекомендации при необходимости повышать предсказательную силу модели.
